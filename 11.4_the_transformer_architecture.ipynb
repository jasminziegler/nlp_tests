{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.4 The Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emerged in 2017 - took over rnns in nlp tasks \\\n",
    "Attention is all you need paper \\\n",
    "- neural attention: used to build powerful sequence models that don't require recurrent or convolutional layers \\\n",
    "\n",
    "REVOLUTION in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.1 Understanding self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogy: as I am reading the DLWP book, skipping some parts, going to the one I need to study for my PhD \\\n",
    "--> what if models did the same? \\\n",
    "simple but powerful idea:\n",
    "- not all input information is equally important for a specific task\n",
    "- models should \"pay more attention\" to some features and \"pay less less attention\" to others \n",
    "\n",
    "examples: \\\n",
    "max pooling in convnets is a \"all or nothing\" form of attention - keep the most important feature and discard the rest in this spatial region \\\n",
    "TF-IDF normalization assigns importance scores to tokens depending on how much information they are likely to carry - important tokens get boosted, irrelevant tokens get faded out (\"and\", \"or\", etc) = continuous form of attention\n",
    "\n",
    "\n",
    "many forms of attention, but ALL start by computing importance scores for a set of features - high scores for more relevant features, low scores for less relevant ones\n",
    "\n",
    "ATTENTION can also be used to make features \"context-aware\" - meaning of a word is usually context-specific\n",
    "\n",
    "SELF-ATTENTION: modulate the representation of a token by using the representations of related tokens in the sequence \\\n",
    "this produces context-aware token representations, e.g.: \n",
    "\n",
    "\"The train left the station on time\" - consider station - \"train\" is the improtant contextual information (not radio station e.g.) so for the word station, station itself would get the highest self-attention score 1.0 and train the second highest 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras has a built-in layer MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalized Self-Attention: The Query-Key-Value Model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee20aa2885cadc07e824ce5082d40bca942426616eda434cad5578791d33ff8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
