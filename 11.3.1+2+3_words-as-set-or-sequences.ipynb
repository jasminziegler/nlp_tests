{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 approaches for representing groups of words: Sets and sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.1 Preparing the IMDB movie reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset and uncompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "! cat ../datasets/aclImdb/train/pos/4077_10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare validation set - move 20% of training text files to new dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/user/development/datasets/aclImdb/val/neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_364/834173951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"neg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/user/development/datasets/aclImdb/val/neg'"
     ]
    }
   ],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"/home/user/development/datasets/aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text_dataset_from_directory utiliy = create a batched Dataset of text and their labels from a directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 13:31:41.177059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-12 13:31:41.177115: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-12 13:31:41.177131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (05f1986588ca): /proc/driver/nvidia/version does not exist\n",
      "2022-01-12 13:31:41.178078: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    base_dir / \"train\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    base_dir / \"val\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    base_dir / \"test\", batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'One reviewer notes that it does not seem to matter what Welles actually says or does, he moves you. I concur. He was and remains a unique force in film. More than a triple threat who could act, write and direct, he had a genius uniquely suited to film. One can consider whether in an earlier age he would have been a painter. This film certainly reinforces that impression. A musician, a theatre actor, an heir to Shakespeare? hard to tell but I am very grateful that his time cam with film and he have him captured on film. I like the accent. I like the face, the size, the style, the mind and the games. I love all of his movies and wish there were more. I particularly love how other actors interacted with him on film. Many were never better or at least somehow different with him because he was o firmly there. Even towards the end when his beauty was ruined, perhaps by his own intent, he was impossible to ignore and he made every scene he was in. Rita was a gorgeous blonde -- a Lana Turner look alike but perhaps even lovelier and even then the eye goes to Welles and one wishes for another minute, another film, another hour in his company. That is why we all wish we could come upon the lost scraps cut from his films because we know, we all know, that there is not part of him not worthy of our time. Watch it and be grateful for the chance.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.2: Processing words as a set: the bag-of-words-approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest way to encode a piece of text: discard order and treat it as a bag of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's process raw text datasets with a TextVectorization layer = multi-hot encoded binary word vectors (vector dimensions as big as my number of words with 0s almost everywhere and 1s for dimensions that encode words present in the text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unigrams with binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000,   # limit vocabulary to the most 20k frequent words - 20k is good for text classification\n",
    "    output_mode=\"multi_hot\"\n",
    ")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)  # prepare a dataset that only yields raw text inputs (no labels)\n",
    "text_vectorization.adapt(text_only_train_ds)  # use dataset to index the dataset vocabulary via adapt()\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_1gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_1gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect output of one of these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'float32'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in binary_1gram_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)     \n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's write a reusable model-building function that we'll use in all of our experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 31s 48ms/step - loss: 0.4085 - accuracy: 0.8280 - val_loss: 0.3020 - val_accuracy: 0.8806\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2746 - accuracy: 0.9003 - val_loss: 0.3046 - val_accuracy: 0.8860\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2480 - accuracy: 0.9155 - val_loss: 0.3273 - val_accuracy: 0.8804\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2294 - accuracy: 0.9229 - val_loss: 0.3401 - val_accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9257 - val_loss: 0.3526 - val_accuracy: 0.8844\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9285 - val_loss: 0.3717 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2127 - accuracy: 0.9302 - val_loss: 0.3965 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2124 - accuracy: 0.9326 - val_loss: 0.3898 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9330 - val_loss: 0.3982 - val_accuracy: 0.8738\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9366 - val_loss: 0.4028 - val_accuracy: 0.8752\n",
      "782/782 [==============================] - 91s 115ms/step - loss: 0.2949 - accuracy: 0.8848\n",
      "Test acc: 0.885\n"
     ]
    }
   ],
   "source": [
    "#model was already trained - just load the model checkpoint here\n",
    "\n",
    "model = get_model()\n",
    "#model.summary()\n",
    "\n",
    "#callbacks = [\n",
    "#    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True)\n",
    "#]\n",
    "#model.fit(binary_1gram_train_ds.cache(),    # we call cache() on the datasets to cache them in memory - only do preprocessing once during 1st \n",
    "#          validation_data=binary_1gram_val_ds.cache(),  # epoch and reuse preprocessed texts for the following epochs\n",
    "#          epochs=10,                                    # can only be done if the data is small enough to fit in memory\n",
    "#          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"binary_1gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1] :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigrams with binary encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. {\"the\", \"the cat\", \"cat\", \"cat sat\", \"sat\", \"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextVectorization layer can be configured to return arbitrary N-grams: bigrams, trigrams, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"multi_hot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see how our model performs when trained on such binary encoded bags of bigrams - any difference to unigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.3788 - accuracy: 0.8393 - val_loss: 0.2828 - val_accuracy: 0.8886\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9121 - val_loss: 0.2857 - val_accuracy: 0.8926\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2255 - accuracy: 0.9287 - val_loss: 0.3047 - val_accuracy: 0.8952\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2039 - accuracy: 0.9368 - val_loss: 0.3211 - val_accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1957 - accuracy: 0.9420 - val_loss: 0.3479 - val_accuracy: 0.8912\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1882 - accuracy: 0.9438 - val_loss: 0.3539 - val_accuracy: 0.8920\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1865 - accuracy: 0.9478 - val_loss: 0.3627 - val_accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1882 - accuracy: 0.9505 - val_loss: 0.3709 - val_accuracy: 0.8922\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1813 - accuracy: 0.9491 - val_loss: 0.3775 - val_accuracy: 0.8932\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1799 - accuracy: 0.9498 - val_loss: 0.3902 - val_accuracy: 0.8926\n",
      "782/782 [==============================] - 26s 33ms/step - loss: 0.2706 - accuracy: 0.8974\n",
      "Test acc: 0.897\n"
     ]
    }
   ],
   "source": [
    "#model was already trained - just load the model checkpoint here\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "binary_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "binary_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "model = get_model()\n",
    "# model.summary()\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
    "#                                     save_best_only=True)\n",
    "# ]\n",
    "# model.fit(binary_2gram_train_ds.cache(),\n",
    "#           validation_data=binary_2gram_val_ds.cache(),\n",
    "#           epochs=10,\n",
    "#           callbacks=callbacks)\n",
    "model = keras.models.load_model(\"binary_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy is improved! -> local order is pretty important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams with TF-IDF encoding: add more information by counting how many times each word/n-gram occurs - histogram of words over text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. {\"the\": 2, \"the cat\": 1, \"cat\": 1, \"cat sat\": 1, \"sat\": 1,\n",
    "\"sat on\": 1, \"on\": 1, \"on the\": 1, \"the mat: 1\", \"mat\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count bigram occurences with TextVectorization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words like \"th\", \"a\", \"is\", \"are\" will always be dominant in texts -> normalization could solve it, but would wreck sparsity of having many zeros in vectorized sentences - computational effort increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution: TF-IDF = term frequency, inverse document frequency --> compare the term frequency in the current sample with the frequency over the entire document -> just change output mode in TextVectorization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"tf_idf\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,033\n",
      "Trainable params: 320,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.5076 - accuracy: 0.7528 - val_loss: 0.3363 - val_accuracy: 0.8764\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3549 - accuracy: 0.8468 - val_loss: 0.3060 - val_accuracy: 0.8866\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3098 - accuracy: 0.8760 - val_loss: 0.3189 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2715 - accuracy: 0.8942 - val_loss: 0.3357 - val_accuracy: 0.8812\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2497 - accuracy: 0.9038 - val_loss: 0.3391 - val_accuracy: 0.8876\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2299 - accuracy: 0.9146 - val_loss: 0.3662 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2236 - accuracy: 0.9157 - val_loss: 0.3799 - val_accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2160 - accuracy: 0.9197 - val_loss: 0.3919 - val_accuracy: 0.8728\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2099 - accuracy: 0.9216 - val_loss: 0.3764 - val_accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2032 - accuracy: 0.9252 - val_loss: 0.3850 - val_accuracy: 0.8696\n",
      "782/782 [==============================] - 23s 28ms/step - loss: 0.2996 - accuracy: 0.8863\n",
      "Test acc: 0.886\n"
     ]
    }
   ],
   "source": [
    "#model was already trained - just load the model checkpoint here\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)        # will learn tf-idf weights as well as vocabulary\n",
    "\n",
    "tfidf_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "model = get_model()\n",
    "# model.summary()\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
    "#                                     save_best_only=True)\n",
    "# ]\n",
    "# model.fit(tfidf_2gram_train_ds.cache(),\n",
    "#           validation_data=tfidf_2gram_val_ds.cache(),\n",
    "#           epochs=10,\n",
    "#           callbacks=callbacks)\n",
    "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing words as a sequence - the sequence model approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order matters! as seen in 11.3.2 - inducing order into our data like in bigrams yields better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### represent my input samples as sequences of integer indices - where each integer stands for one word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use in this chapter: Bidirectional RNNs / bidirectional LSTMs - SOTA for sequence modeling 2016-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nowadays: almost universally done with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,      # we truncate the inputs after the first 600 words (average review length is 233)\n",
    ")                                           # only 5% of reviews are longer than 600 words\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest way to convert our integer sequences to vector sequences: one-hot encode the ints, add simple bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot_1 (TFOpLambda)   (None, None, 20000)       0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               5128448   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,128,513\n",
      "Trainable params: 5,128,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")      # one input is a sequence of integers\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)         # encode the ints into binary 20,000-dimensional vectors\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)     # add a bidirectional LSTM\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)      # add a classification layer\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 15:17:37.367506: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1536000000 exceeds 10% of free system memory.\n",
      "2022-01-11 15:17:37.867303: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1536000000 exceeds 10% of free system memory.\n",
      "2022-01-11 15:17:37.867437: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1536000000 exceeds 10% of free system memory.\n",
      "2022-01-11 15:18:08.540364: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1536000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/625 [..............................] - ETA: 23:12:06 - loss: 0.6942 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 15:19:48.523781: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1536000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/625 [..............................] - ETA: 2:32:05 - loss: 0.6941 - accuracy: 0.4773"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
    "          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
    "print(f\"Test accuracy: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result: this is super slow because each input sample is encoded as a matrix of size (600, 20000) - 600 words per sample, 20k possible words -> tht's 12MIO floats for a single movie review \\\n",
    "one-hot encoding is not a good idea, better: word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### understanding word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when I do one-hot encoding, i assume \"that the different tokens I am encoding are all independent from each other\" \\\n",
    "one-hot vectors are all orthogonal to one another - but vector for \"movie\" and \"film\" should be the same or very close vectors \\\n",
    "geometric relationship between word vectors should reflect semantic relationship between words!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word embeddings are vector representations that map human language into a structures geometric space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word embeddings: low dimensional float vectors = dense vectors; structured and structure is learned from data \\\n",
    "similar words get embedded in close locations and specific directions in the embedding space are meaningful \\\n",
    "common meaningful geometric transformations: \"gender\" or \"plural\" vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of obtaining word embeddings: \\\n",
    "1: learn word embeddings jointly with main learning task \\\n",
    "2: load pretrained word embeddings into my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Learn word embeddings with the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding layer: dictionary that maps integer indices (stand for specific words) to dense vectors \\\n",
    "takes ints as input, loops up these ints in an internal dictionary and returns the associated vectors \\\n",
    "word index -> embedding layer -> corresponding word vector \\\n",
    "input: rank2 tensor of ints of shape (batch_size, sequence_length) \\\n",
    "output: 3D floating-point tensor of shape (batch_size, sequence_length, embedding_dimensionality) \\\n",
    "weights randomly initialized (like with any other layer) - gradually adjusted via backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               73984     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 198s 312ms/step - loss: 0.4718 - accuracy: 0.7855 - val_loss: 0.3919 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 187s 299ms/step - loss: 0.3036 - accuracy: 0.8878 - val_loss: 0.3233 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 191s 306ms/step - loss: 0.2417 - accuracy: 0.9161 - val_loss: 0.4084 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 195s 312ms/step - loss: 0.2006 - accuracy: 0.9314 - val_loss: 0.3612 - val_accuracy: 0.8832\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 197s 315ms/step - loss: 0.1777 - accuracy: 0.9413 - val_loss: 0.3514 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 182s 292ms/step - loss: 0.1457 - accuracy: 0.9534 - val_loss: 0.4771 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 188s 300ms/step - loss: 0.1322 - accuracy: 0.9588 - val_loss: 0.4400 - val_accuracy: 0.8808\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 194s 309ms/step - loss: 0.1066 - accuracy: 0.9678 - val_loss: 0.4401 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 176s 281ms/step - loss: 0.0899 - accuracy: 0.9726 - val_loss: 0.5131 - val_accuracy: 0.8736\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 168s 268ms/step - loss: 0.0778 - accuracy: 0.9757 - val_loss: 0.7198 - val_accuracy: 0.8516\n",
      "782/782 [==============================] - 73s 92ms/step - loss: 0.3552 - accuracy: 0.8662\n",
      "Test acc: 0.866\n"
     ]
    }
   ],
   "source": [
    "#model was already trained - just load the model checkpoint here\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
    "#                                     save_best_only=True)\n",
    "# ]\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, \n",
    "#           callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### understanding padding and masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding: \\\n",
    "what's hurting our model performance: input sequences are full of zeros which comes from output_sequence_length=max_length (600) in TextVectorization -> this cuts off reviews longer than 600 tokens BUT ALSO fills up shorter reviews with zeros = padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "masking: \\ \n",
    "we use a bidirectional RNN - two RNN layers running in parallel \\\n",
    "1 processing tokens in their natural order (will spend the last iterations seeing only vectors that encode padding) \\\n",
    "1 processing the same tokens in reverse \\\n",
    "way to tell the RNN to skip padding iterations = masking \\\n",
    "\\\n",
    "mask = tensor of ones and zeros (true/false bools) of shape (batch_size, sequence_length) - indicates which samples should be skipped (0 or false) or which should be processed (1 or true) \\\n",
    "turned off by default - turn on in Embedding layer with mask_zero=True \\ \n",
    "retrieve mask with compute_mask() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=10, output_dim=256, mask_zero=True)\n",
    "some_input = [\n",
    "     [4, 3, 2, 1, 0, 0, 0],\n",
    "     [5, 4, 3, 2, 1, 0, 0],\n",
    "     [2, 1, 0, 0, 0, 0, 0]]\n",
    "\n",
    "mask = embedding_layer.compute_mask(some_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 227s 355ms/step - loss: 0.3998 - accuracy: 0.8160 - val_loss: 0.2916 - val_accuracy: 0.8762\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 227s 363ms/step - loss: 0.2323 - accuracy: 0.9112 - val_loss: 0.2902 - val_accuracy: 0.8876\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 244s 390ms/step - loss: 0.1710 - accuracy: 0.9370 - val_loss: 0.3170 - val_accuracy: 0.8796\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 232s 371ms/step - loss: 0.1236 - accuracy: 0.9568 - val_loss: 0.3728 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.0926 - accuracy: 0.9675 - val_loss: 0.3611 - val_accuracy: 0.8768\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 219s 350ms/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.4604 - val_accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 218s 349ms/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 0.4873 - val_accuracy: 0.8722\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 215s 344ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 0.5207 - val_accuracy: 0.8662\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.6066 - val_accuracy: 0.8690\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.6634 - val_accuracy: 0.8718\n",
      "782/782 [==============================] - 68s 84ms/step - loss: 0.3154 - accuracy: 0.8773\n",
      "Test acc: 0.877\n"
     ]
    }
   ],
   "source": [
    "#model was already trained - just load the model checkpoint here\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
    "#                                     save_best_only=True)\n",
    "# ]\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
    "#           callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful if: \\\n",
    "too little training data to learn truly powerful embeddings of my vocabulary \\\n",
    "same as in CNNS - images as well as language have fairly generic features - visual or semantic respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well-known word embeddings - generally computed using word-occurence statistics (which words co-occur in sentences): \\\n",
    "word2vec algorithm by google in 2013: famous word-embedding scheme, captures specific semantic properties such as gender \\\n",
    "GloVe: global vectors for word representation, Stanford 2014 (based on factorizing a matrix of word co-occurence statistics, from Wikipedia and Common Crawl data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use GloVe embeddings in a keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-12 15:39:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-01-12 15:39:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-01-12 15:39:50--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  1.58MB/s    in 4m 17s  \n",
      "\n",
      "2022-01-12 15:44:07 (3.20 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's parse the unzipped file to build an index that maps words as strings to their vector representations from the glove dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's build an embedding matrix that you can load into an Embedding layer - it must be of shape (max_words, embedding_dim), where each entry i contains the embedding_dim-dimensional vector for the word of index i in the reference word index (built during tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()  #retrieve the vocabulary indexed by our previous TextVectorization layer\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))  # use it to create a mapping from words to their index in the vocab\n",
    "\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))    # prepare a matrix that we'll fill with the GloVe vectors\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector      # fill entry i in the matrix with the word vector for indexx i; words not found in embedding index will be zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a Constant initializer to load the pretrained embeddings in an embedding layer - we freeze the layer via trainable=False to not disrupt the pretrained representations during training (to not \"learn\" them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    max_tokens, \n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               34048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,034,113\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 180s 277ms/step - loss: 0.5709 - accuracy: 0.6991 - val_loss: 0.4657 - val_accuracy: 0.7926\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 170s 272ms/step - loss: 0.4468 - accuracy: 0.7969 - val_loss: 0.4013 - val_accuracy: 0.8190\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 170s 271ms/step - loss: 0.3954 - accuracy: 0.8263 - val_loss: 0.3750 - val_accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 168s 268ms/step - loss: 0.3645 - accuracy: 0.8439 - val_loss: 0.3912 - val_accuracy: 0.8250\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 168s 268ms/step - loss: 0.3322 - accuracy: 0.8599 - val_loss: 0.3448 - val_accuracy: 0.8552\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 164s 262ms/step - loss: 0.3141 - accuracy: 0.8702 - val_loss: 0.3925 - val_accuracy: 0.8308\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 0.2979 - accuracy: 0.8768 - val_loss: 0.3644 - val_accuracy: 0.8366\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 169s 270ms/step - loss: 0.2769 - accuracy: 0.8880 - val_loss: 0.3231 - val_accuracy: 0.8690\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 166s 265ms/step - loss: 0.2636 - accuracy: 0.8925 - val_loss: 0.3189 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 171s 273ms/step - loss: 0.2516 - accuracy: 0.9003 - val_loss: 0.3175 - val_accuracy: 0.8702\n",
      "782/782 [==============================] - 67s 82ms/step - loss: 0.2964 - accuracy: 0.8751\n",
      "Test ass: 0.875\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
    "          callbacks=callbacks)\n",
    "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
    "print(f\"Test ass: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee20aa2885cadc07e824ce5082d40bca942426616eda434cad5578791d33ff8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
